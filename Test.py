import os
import re
from nltk import sent_tokenize

def main():
    print()

    with open( os.path.join(os.path.dirname(__file__), "Corpus/Winter.txt"), mode="r", encoding="utf-8") as file:
        rawText = file.read()

        lines = rawText.split("\n")
        sentences = sent_tokenize(rawText)

        for sent in sentences:
            print(sent.replace("\n", ""))

        


main()