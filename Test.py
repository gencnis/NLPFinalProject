import os
import re
from nltk import sent_tokenize

def main():
    # print()

    # with open( os.path.join(os.path.dirname(__file__), "Corpus/Winter.txt"), mode="r", encoding="utf-8") as file:
    #     rawText = file.read()

    #     lines = rawText.split("\n")
    #     sentences = sent_tokenize(rawText)

    #     for sent in sentences:
    #         print(sent.replace("\n", ""))


    print( [1, 2, 3, 4] * 0.5)

        


main()